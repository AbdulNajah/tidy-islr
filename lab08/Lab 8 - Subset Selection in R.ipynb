{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab on Subset Selection in R comes from p. 244-247 of \"Introduction to Statistical Learning with Applications in R\" by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5.1 Best Subset Selection\n",
    "\n",
    "Here we apply the best subset selection approach to the Hitters data. We\n",
    "wish to predict a baseball player’s Salary on the basis of various statistics\n",
    "associated with performance in the previous year. Let's take a quick look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(ISLR)\n",
    "head(Hitters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we note that the ${\\tt Salary}$ variable is missing for some of the\n",
    "players. The ${\\tt is.na()}$ function can be used to identify the missing observations. It returns a vector of the same length as the input vector, with a ${\\tt TRUE}$ value\n",
    "for any elements that are missing, and a ${\\tt FALSE}$ value for non-missing elements.\n",
    "The ${\\tt sum()}$ function can then be used to count all of the missing elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(is.na(Hitters$Salary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that ${\\tt Salary}$ is missing for 59 players. The ${\\tt na.omit()}$ function\n",
    "removes all of the rows that have missing values in any variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the dimensions of the original Hitters data (322 rows x 20 columns)\n",
    "dim(Hitters)\n",
    "\n",
    "# Drop any rows the contain missing values\n",
    "Hitters = na.omit(Hitters)\n",
    "\n",
    "# Print the dimensions of the modified Hitters data (263 rows x 20 columns)\n",
    "dim(Hitters)\n",
    "\n",
    "# One last check: should return 0\n",
    "sum(is.na(Hitters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ${\\tt regsubsets()}$ function (part of the ${\\tt leaps}$ library) performs best subset selection by identifying the best model that contains a given number of predictors, where **best** is quantified using RSS. The syntax is the same as for ${\\tt lm()}$. The ${\\tt summary()}$ command outputs the best set of variables for\n",
    "each model size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(leaps)\n",
    "regfit.full = regsubsets(Salary~.,Hitters)\n",
    "summary(regfit.full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An asterisk (\"\\*\") indicates that a given variable is included in the corresponding\n",
    "model. For instance, this output indicates that the best two-variable model\n",
    "contains only Hits and CRBI. By default, $\\tt{regsubsets()}$ only reports results\n",
    "up to the best eight-variable model. But the ${\\tt nvmax}$ option can be used\n",
    "in order to return as many variables as are desired. Here we fit up to a\n",
    "19-variable model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regfit.full=regsubsets(Salary~.,data=Hitters ,nvmax = 19)\n",
    "reg.summary = summary(regfit.full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that rather than letting the results of our call to the ${\\tt summary()}$ function print to the screen, we've saved the results to a variable called ${\\tt reg.summary}$. That way, we can access just the parts we need. Let's see what's in there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names(reg.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! In addition to the verbose output we get when we print the summary to the screen, the ${\\tt summary()}$ function also returns $R^2 (\\tt{rsq})$, RSS, adjusted $R^2$, $C_p$, and BIC. We can examine these to try to select the best overall model. Let's start by looking at $R^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg.summary$rsq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the $R^2$ statistic increases from 32% when only\n",
    "one variable is included in the model to almost 55% when all variables\n",
    "are included. As expected, the $R^2$ statistic increases monotonically as more\n",
    "variables are included.\n",
    "\n",
    "Plotting RSS, adjusted $R^2$, $C_p$, and BIC for all of the models at once will\n",
    "help us decide which model to select. Note the ${\\tt type=\"l\"}$ option tells ${\\tt R}$ to\n",
    "connect the plotted points with lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up a 2x2 grid so we can look at 4 plots at once\n",
    "par(mfrow=c(2,2))\n",
    "plot(reg.summary$rss, xlab = \"Number of Variables\", ylab = \"RSS\", type = \"l\")\n",
    "plot(reg.summary$adjr2, xlab = \"Number of Variables\", ylab = \"Adjusted RSq\", type = \"l\")\n",
    "\n",
    "# We will now plot a red dot to indicate the model with the largest adjusted R^2 statistic.\n",
    "# The which.max() function can be used to identify the location of the maximum point of a vector\n",
    "    \n",
    "which.max(reg.summary$adjr2) # 11\n",
    "\n",
    "# The points() command works like the plot() command, except that it puts points \n",
    "# on a plot that has already been created instead of creating a new plot\n",
    "points(11,reg.summary$adjr2[11], col =\"red\", cex = 2, pch = 20)\n",
    "\n",
    "# We'll do the same for C_p and BIC, this time looking for the models with the SMALLEST statistic\n",
    "plot(reg.summary$cp, xlab = \"Number of Variables\", ylab = \"Cp\", type = \"l\")\n",
    "which.min(reg.summary$cp) # 10\n",
    "points(10, reg.summary$cp[10], col = \"red\", cex = 2, pch = 20)\n",
    "\n",
    "plot(reg.summary$bic, xlab = \"Number of Variables\", ylab = \"BIC\", type = \"l\")\n",
    "which.min(reg.summary$bic) # 6\n",
    "points(6, reg.summary$bic[6], col = \"red\", cex = 2, pch = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that in the second step of our selection process, we narrowed the field down to just one model on any $k<=p$ predictors. We see that according to BIC, the best performer is the model with 6 variables. According to $C_p$, 10 variables. Adjusted $R^2$ suggests that 11 might be best. Again, no one measure is going to give us an entirely accurate picture... but they all agree that a model with 5 or fewer predictors is insufficient, and a model with more than 12 is overfitting.\n",
    "\n",
    "The ${\\tt regsubsets()}$ function has a built-in ${\\tt plot()}$ command which can\n",
    "be used to display the selected variables for the best model with a given\n",
    "number of predictors, ranked according to a chosen statistic.  The top row of each plot contains a black square for each variable selected according to the optimal model associated with that statistic. \n",
    "\n",
    "To find out more about this function, type ${\\tt ?plot.regsubsets}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(regfit.full,scale=\"r2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, $R^2$ is maximized by the model that contains all 20 predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(regfit.full,scale=\"adjr2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusted $R^2$ downselects to just 11 predictors. We can use the ${\\tt coef()}$ function to see which predictors made the cut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coef(regfit.full,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(regfit.full,scale=\"Cp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$C_p$ downselects further, dropping the ${\\tt LeagueN}$ predictor and bringing the number down to 10: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coef(regfit.full,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(regfit.full,scale=\"bic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that several models share a BIC close to −150. However, the model\n",
    "with the lowest BIC is the six-variable model that contains only ${\\tt AtBat,\n",
    "Hits, Walks, CRBI, DivisionW,}$ and ${\\tt PutOuts}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coef(regfit.full,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5.2 Forward and Backward Stepwise Selection\n",
    "We can also use the ${\\tt regsubsets()}$ function to perform forward stepwise\n",
    "or backward stepwise selection, using the argument ${\\tt method=\"forward\"}$ or\n",
    "${\\tt method=\"backward\"}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Forward\n",
    "regfit.fwd=regsubsets(Salary~.,data=Hitters,nvmax=19,method=\"forward\")\n",
    "summary(regfit.fwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Backward\n",
    "regfit.bwd=regsubsets(Salary~.,data=Hitters,nvmax=19,method=\"backward\")\n",
    "summary(regfit.bwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that using forward stepwise selection, the best onevariable\n",
    "model contains only ${\\tt CRBI}$, and the best two-variable model additionally\n",
    "includes ${\\tt Hits}$. For this data, the best one-variable through six-variable\n",
    "models are each identical for best subset and forward selection.\n",
    "However, the best seven-variable models identified by forward stepwise selection,\n",
    "backward stepwise selection, and best subset selection are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coef(regfit.full,7)\n",
    "coef(regfit.fwd,7)\n",
    "coef(regfit.bwd,7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
